{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "271ad386",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce327c",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe958347",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| Required to import, and briefly discuss, the libraries that will be used throughout analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "112d16df",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| Load the data from the `train and test` file into a DataFrame. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading training dataset\n",
    "df_train = pd.read_csv(\"train.csv\") \n",
    "\n",
    "# loading testing dataset\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7631be",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| Perform an in-depth analysis of all the variables in the DataFrame. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90630617",
   "metadata": {},
   "source": [
    "##### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "print(df_train.head(10), \"\\n\")\n",
    "print(df_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displays the number of rows and columns \n",
    "# df_train.shape\n",
    "df_test.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "Displays info about the columns\n",
    "'''\n",
    "df_train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb0f5e8",
   "metadata": {},
   "source": [
    "#### Converting the sentiments form number to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec84a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiments from numbers to words\n",
    "\"\"\" The followinng function takes the original dataframe as a parameter then create a copy of it and\n",
    "then corverts the sentiments from numbers to words \"\"\"\n",
    "\n",
    "def update(df):\n",
    "    df = df_train.copy()\n",
    "    sentiment = df['sentiment']\n",
    "    word_sentiment = []\n",
    "\n",
    "    for i in sentiment :\n",
    "        if i == 1 :\n",
    "            word_sentiment.append('Pro')\n",
    "        elif i == 0 :\n",
    "            word_sentiment.append('Neutral')\n",
    "        elif i == -1 :\n",
    "            word_sentiment.append('Anti')\n",
    "        else :\n",
    "            word_sentiment.append('News')\n",
    "\n",
    "    df['sentiment'] = word_sentiment\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train = update(df_train)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdef569",
   "metadata": {},
   "source": [
    "#### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ad2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_tweets = round((1-(df_train['message'].nunique()/len(df_train['message'])))*100,2)\n",
    "print('Duplicate tweets percentage:', duplicate_tweets,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8a3a23",
   "metadata": {},
   "source": [
    "The duplicates are caused by the retweets, So about 10,5 of the tweets in our dataset are Retweets(RT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecfed7f",
   "metadata": {},
   "source": [
    "#### Check Number of tweets for each sentimenrt class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89837c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6372be",
   "metadata": {},
   "source": [
    "#### Check distribution of sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='sentiment', data=df_train)\n",
    "plt.title('Distribution of Sentiments')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66eaa3f",
   "metadata": {},
   "source": [
    "#### Proportion of tweets in each sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1fc71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the proportion of tweets in each sentiment\n",
    "perc = df_train['sentiment'].value_counts()\n",
    "perc.plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Proportion of tweets in each sentiment')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063bbe8f",
   "metadata": {},
   "source": [
    "The proportion of tweets in each in each sentiment shows that the Pro climate change is the majority "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweet Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Average length of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the characteristics of the tweet text\n",
    "df_train['tweet_length'] = df_train['message'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Distribution of tweet length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_train['tweet_length'], bins=50, kde=True)\n",
    "plt.title('Distribution of Tweet Lengths')\n",
    "plt.xlabel('Tweet Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50bab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the length tweets for each class using a box plot\n",
    "\n",
    "sns.boxplot(x=df_train['sentiment'], y=df_train['tweet_length'], data=df_train)\n",
    "plt.title('Tweet length for each class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Common words and phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Concatenates the all the tweets into a single string\n",
    "and tokenises the text into individual words and\n",
    "outputs the most common words & its frequencies\n",
    "'''\n",
    "all_text = ' '.join(df_train['message'].astype(str))\n",
    "\n",
    "tokens = word_tokenize(all_text)\n",
    "fdist = FreqDist(tokens)\n",
    "common_words = fdist.most_common(10)\n",
    "print(\"Common Words:\", common_words)\n",
    "\n",
    "bi_grams = list(bigrams(tokens))\n",
    "bi_gram_freq = FreqDist(bi_grams)\n",
    "common_bigrams = bi_gram_freq.most_common(10)\n",
    "print(\"Common Bigrams:\", common_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1f6c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df_train['message'].values\n",
    "\n",
    "if len(tweets) > 0:\n",
    "    positive_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(tweets))\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(positive_wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('WordCloud for all tweets')\n",
    "else:\n",
    "    print('No tweets found.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Verify for any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec933f0",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data engineering ⚡ |\n",
    "| :--------------------------- |\n",
    "| Clean the dataset, and possibly create new features - as identified in the EDA phase. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in df_train:\\n\", df_train.isnull().sum())\n",
    "print(\"Missing values in df_test:\\n\", df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the message column\n",
    "def clean_text(text):\n",
    "    # Remove mentions (@user), URLs, and special characters\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)  # Remove special characters\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_text = [word for word in tokens]\n",
    "    \n",
    "    # Join the filtered words back into a sentence\n",
    "    text = ' '.join(filtered_text)\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting out the X from the target\n",
    "y = df_train['sentiment']\n",
    "X = df_train['message']\n",
    "\n",
    "# Turning text into something your model can read\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=2, stop_words =\"english\")\n",
    "X_vectorized = vectorizer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4178766",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| Create one or more classification models that are able to accurately predict |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the training data into a training set and a validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=.3,shuffle=True, stratify=y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aebf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model and evaluating using the evaluation set\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8472b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC\n",
    "lsvc = LinearSVC(class_weight='balanced')\n",
    "lsvc.fit(X_train, y_train)\n",
    "lsvc_pred = lsvc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc94214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K - nearest neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be21453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Niave bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_pred = nb.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the perfomance of our model on the validations\n",
    "f1_score(y_val, knn_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa99569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our test ready\n",
    "\n",
    "testx = df_test['message']\n",
    "test_vect = vectorizer.transform(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb92ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the test set and adding sentiment column to our original test df\n",
    "y_pred = rfc.predict(test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the test set and adding a sentiment column to our original test df\n",
    "\n",
    "y_pred = rfc.predict(test_vect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5e4217",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a1974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['sentiment'] = y_pred\n",
    "df_test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2600067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['tweetid','sentiment']].to_csv('submission.csv', index =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184102a6",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| Compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cea62eb",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
